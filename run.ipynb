{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "seed = 2453466\n",
    "checkpt_dir = 'checkpoints'\n",
    "dataset = 'MNIST'\n",
    "num_experts = 4\n",
    "input_size = 28 * 28\n",
    "load_initialized_experts = False\n",
    "model_for_initialized_experts = 'blockmodel'\n",
    "optimizer_initialize = 'sgd'\n",
    "learning_rate_initialize = .01\n",
    "weight_decay = 0\n",
    "epochs_init = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import MNISTDataset\n",
    "\n",
    "train_dataset = MNISTDataset(train=True, transformer_names=[\"rotate_left\", \"rotate_left\"])\n",
    "test_dataset = MNISTDataset(train=False, transformer_names=[\"rotate_left\", \"rotate_left\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init seed and training device\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for checkpoints\n",
    "if not os.path.exists(checkpt_dir):\n",
    "    os.mkdir(checkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "from model import Expert, Discriminator\n",
    "experts = [Expert(dataset=dataset, input_size=input_size).to(device) for _ in range(num_experts)]\n",
    "discriminator = Discriminator(dataset=dataset, input_size=input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "loss_initial = torch.nn.MSELoss(reduction='mean')\n",
    "criterion = torch.nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing expert [1] as identity on preturbed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:10<00:00, 73.42it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [00:10<00:31, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [1] expert [1] loss 0.7343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:11<00:00, 65.99it/s]\n",
      "Epoch:  50%|█████     | 2/4 [00:22<00:22, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [2] expert [1] loss 0.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:11<00:00, 68.33it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [00:33<00:11, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [3] expert [1] loss 0.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:13<00:00, 59.32it/s]\n",
      "Epoch: 100%|██████████| 4/4 [00:47<00:00, 11.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [4] expert [1] loss 0.3157\n",
      "Initializing expert [2] as identity on preturbed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:17<00:00, 45.30it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [00:17<00:51, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [1] expert [2] loss 0.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:16<00:00, 48.39it/s]\n",
      "Epoch:  50%|█████     | 2/4 [00:33<00:33, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [2] expert [2] loss 0.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:15<00:00, 50.59it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [00:48<00:16, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [3] expert [2] loss 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:14<00:00, 55.11it/s]\n",
      "Epoch: 100%|██████████| 4/4 [01:03<00:00, 15.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [4] expert [2] loss 0.3151\n",
      "Initializing expert [3] as identity on preturbed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:15<00:00, 51.57it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [00:15<00:45, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [1] expert [3] loss 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:16<00:00, 47.59it/s]\n",
      "Epoch:  50%|█████     | 2/4 [00:31<00:31, 15.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [2] expert [3] loss 0.4696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:16<00:00, 46.12it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [00:48<00:16, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [3] expert [3] loss 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:18<00:00, 43.34it/s]\n",
      "Epoch: 100%|██████████| 4/4 [01:06<00:00, 16.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [4] expert [3] loss 0.3135\n",
      "Initializing expert [4] as identity on preturbed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:18<00:00, 42.79it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [00:18<00:54, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [1] expert [4] loss 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:19<00:00, 40.81it/s]\n",
      "Epoch:  50%|█████     | 2/4 [00:37<00:37, 18.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [2] expert [4] loss 0.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:14<00:00, 55.85it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [00:51<00:16, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [3] expert [4] loss 0.3725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:15<00:00, 50.48it/s]\n",
      "Epoch: 100%|██████████| 4/4 [01:06<00:00, 16.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [4] expert [4] loss 0.3152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Experts as approximately Identity on Transformed Data\n",
    "from trainer import initialize_expert\n",
    "\n",
    "for i, expert in enumerate(experts):\n",
    "    if load_initialized_experts:\n",
    "        path = os.path.join(checkpt_dir, f'{model_for_initialized_experts}_E_{i+1}_init.pth')\n",
    "        init_weights(expert, path)\n",
    "    else:\n",
    "        if optimizer_initialize == 'adam':\n",
    "            optimizer_E = torch.optim.Adam(expert.parameters(), lr=learning_rate_initialize,\n",
    "                                                weight_decay=weight_decay)\n",
    "        elif optimizer_initialize == 'sgd':\n",
    "            optimizer_E = torch.optim.SGD(expert.parameters(), lr=learning_rate_initialize,\n",
    "                                                weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        initialize_expert(\n",
    "            epochs=epochs_init, \n",
    "            architecture_name=model_for_initialized_experts, \n",
    "            expert=expert, \n",
    "            i=i, \n",
    "            optimizer=optimizer_E, \n",
    "            loss=loss_initial, \n",
    "            data_train=train_loader,\n",
    "            device=device,\n",
    "            checkpt_dir=checkpt_dir,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizers_E = []\n",
    "for i in range(args.num_experts):\n",
    "    if args.optimizer_experts == 'adam':\n",
    "        optimizer_E = torch.optim.Adam(experts[i].parameters(), lr=args.learning_rate_expert,\n",
    "                                        weight_decay=args.weight_decay)\n",
    "    elif args.optimizer_experts == 'sgd':\n",
    "        optimizer_E = torch.optim.SGD(experts[i].parameters(), lr=args.learning_rate_expert,\n",
    "                                        weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    optimizers_E.append(optimizer_E)\n",
    "if args.optimizer_discriminator == 'adam':\n",
    "    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.learning_rate_discriminator,\n",
    "                                    weight_decay=args.weight_decay)\n",
    "elif args.optimizer_discriminator == 'sgd':\n",
    "    optimizer_D = torch.optim.SGD(discriminator.parameters(), lr=args.learning_rate_discriminator,\n",
    "                                    weight_decay=args.weight_decay)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
