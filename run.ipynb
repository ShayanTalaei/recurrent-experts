{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "seed = 2453466\n",
    "checkpt_dir = 'checkpoints'\n",
    "dataset = 'MNIST'\n",
    "num_experts = 4\n",
    "input_size = 28 * 28\n",
    "load_initialized_experts = False\n",
    "model_for_initialized_experts = 'blockmodel'\n",
    "optimizer_initialize = 'adam'\n",
    "learning_rate_initialize = .1\n",
    "weight_decay = .1\n",
    "epochs_init = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import MNISTDataset\n",
    "\n",
    "train_dataset = MNISTDataset(train=True, transformer_names=[\"rotate_left\", \"rotate_left\"])\n",
    "test_dataset = MNISTDataset(train=False, transformer_names=[\"rotate_left\", \"rotate_left\"])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init seed and training device\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for checkpoints\n",
    "if not os.path.exists(checkpt_dir):\n",
    "    os.mkdir(checkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "from model import Expert, Discriminator\n",
    "experts = [Expert(dataset=dataset, input_size=input_size).to(device) for _ in range(num_experts)]\n",
    "discriminator = Discriminator(dataset=dataset, input_size=input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses\n",
    "loss_initial = torch.nn.MSELoss(reduction='mean')\n",
    "criterion = torch.nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing expert [1] as identity on preturbed data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:38<00:00, 20.53it/s]\n",
      "Epoch:  10%|█         | 1/10 [00:38<05:42, 38.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [1] expert [1] loss 7238.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 782/782 [00:45<00:00, 17.29it/s]\n",
      "Epoch:  20%|██        | 2/10 [01:23<05:38, 42.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization epoch [2] expert [1] loss 7238.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Initialize Experts as approximately Identity on Transformed Data\n",
    "from trainer import initialize_expert\n",
    "\n",
    "for i, expert in enumerate(experts):\n",
    "    if load_initialized_experts:\n",
    "        path = os.path.join(checkpt_dir, f'{model_for_initialized_experts}_E_{i+1}_init.pth')\n",
    "        init_weights(expert, path)\n",
    "    else:\n",
    "        if optimizer_initialize == 'adam':\n",
    "            optimizer_E = torch.optim.Adam(expert.parameters(), lr=learning_rate_initialize,\n",
    "                                                weight_decay=weight_decay)\n",
    "        elif optimizer_initialize == 'sgd':\n",
    "            optimizer_E = torch.optim.SGD(expert.parameters(), lr=learning_rate_initialize,\n",
    "                                                weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        initialize_expert(\n",
    "            epochs=epochs_init, \n",
    "            architecture_name=model_for_initialized_experts, \n",
    "            expert=expert, \n",
    "            i=i, \n",
    "            optimizer=optimizer_E, \n",
    "            loss=loss_initial, \n",
    "            data_train=train_loader,\n",
    "            device=device,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
